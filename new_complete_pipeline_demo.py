"""
CalcMate Complete Neuro-Symbolic Pipeline Demo
---------------------------------------------
Comprehensive demonstration of the entire DSPy neuro-symbolic system:
1. Mathematical similarity retrieval
2. Equation extraction and canonicalization
3. Symbolic equation solving
4. CTransformers LLM reasoning
5. Solution verification
6. Complete end-to-end pipeline flow
7. Performance metrics and analysis
"""

import time
import textwrap
import numpy as np
import json
from typing import List, Dict, Any
from dspy_modules import (
    SmartRetrievalPipeline, 
    SymbolicSolver, 
    Verifier, 
    LLMReasoner,
    initialize_ctransformers_model,
    explain_similarity
)
from pipeline_sequence.embedder import encode_texts
from sympy import symbols, Eq


class CompletePipelineDemo:
    """Comprehensive demo for the complete neuro-symbolic pipeline"""
    
    def __init__(self):
        self.index_path = "output/embeddings/faiss_index_20251015_145706.bin"
        self.idmap_path = "output/embeddings/faiss_id_map_20251015_145706.json"
        self.pipeline = None
        self.llm_model = None
        self.symbolic_solver = SymbolicSolver()
        self.verifier = Verifier()
        self.llm_reasoner = None
        
        # Performance tracking
        self.performance_metrics = {
            'total_queries': 0,
            'symbolic_solutions': 0,
            'llm_solutions': 0,
            'unresolved': 0,
            'total_time': 0,
            'retrieval_times': [],
            'solving_times': [],
            'similarity_scores': []
        }

    def load_complete_system(self):
        """Load the complete neuro-symbolic system with all components"""
        print("üöÄ LOADING COMPLETE NEURO-SYMBOLIC PIPELINE")
        print("=" * 80)
        print("Initializing all components:")
        print("‚Ä¢ Mathematical similarity retrieval (FAISS)")
        print("‚Ä¢ Equation extraction and canonicalization")
        print("‚Ä¢ Symbolic equation solving (SymPy)")
        print("‚Ä¢ CTransformers LLM reasoning")
        print("‚Ä¢ Solution verification")
        print("=" * 80)
        
        try:
            # Initialize CTransformers LLM
            print("\nü§ñ Step 1: Initializing CTransformers LLM...")
            self.llm_model = initialize_ctransformers_model()
            
            if self.llm_model is not None:
                print("‚úÖ CTransformers LLM loaded successfully!")
            else:
                print("‚ö†Ô∏è CTransformers LLM not available, will use fallback methods")
            
            # Load main pipeline with LLM
            print("\nüîÑ Step 2: Loading main neuro-symbolic pipeline...")
            self.pipeline = SmartRetrievalPipeline(
                self.index_path, 
                self.idmap_path,
                llm_model=self.llm_model
            )
            print("‚úÖ Main pipeline loaded successfully!")
            
            # Initialize LLM reasoner
            print("\nüß† Step 3: Initializing LLM reasoner...")
            self.llm_reasoner = LLMReasoner(self.llm_model)
            print("‚úÖ LLM reasoner initialized!")
            
            print("\nüéØ COMPLETE SYSTEM READY!")
            print("=" * 80)
            print("All components loaded and ready for demonstration:")
            print(f"‚Ä¢ Knowledge Base: {len(self.pipeline.problem_db)} math problems")
            print(f"‚Ä¢ Vector Dimension: {self.pipeline.index.d}D")
            print(f"‚Ä¢ LLM Model: {'CTransformers (Llama-2-7B)' if self.llm_model else 'Not available'}")
            print("=" * 80)
            
        except Exception as e:
            print(f"‚ùå Failed to load complete system: {e}")
            import traceback
            traceback.print_exc()
            return False
        return True

    def test_individual_components(self):
        """Test each component individually to verify functionality"""
        print("\nüîß TESTING INDIVIDUAL COMPONENTS")
        print("=" * 80)
        
        # Test 1: Symbolic Solver with LLM extracted equations
        print("\n[1] Testing Symbolic Solver with LLM Equations...")
        print("-" * 50)
        try:
            # Test equations that LLM would extract
            test_equations = ["x + y = 50", "x - y = 10"]
            
            start_time = time.time()
            result = self.symbolic_solver(test_equations)
            solve_time = time.time() - start_time
            
            print(f"‚úÖ Symbolic Solver: {'SUCCESS' if result.success else 'FAILED'}")
            print(f"‚è± Solve Time: {solve_time:.3f} seconds")
            print(f"üìù Input Equations: {test_equations}")
            print(f"üßÆ Solution: {result.solution}")
            print(f"üîç Residuals: {result.residuals}")
            if result.error_msg:
                print(f"‚ùå Error: {result.error_msg}")
        except Exception as e:
            print(f"‚ùå Symbolic Solver Error: {e}")
        
        # Test 2: Verifier with solution
        print("\n[2] Testing Verifier...")
        print("-" * 50)
        try:
            test_equations = ["x + y = 50", "x - y = 10"]
            test_solution = {"x": 30.0, "y": 20.0}
            
            start_time = time.time()
            result = self.verifier(test_equations, test_solution)
            verify_time = time.time() - start_time
            
            print(f"‚úÖ Verifier: {'SUCCESS' if result.verification['ok'] else 'FAILED'}")
            print(f"‚è± Verify Time: {verify_time:.3f} seconds")
            print(f"üìù Input Equations: {test_equations}")
            print(f"üßÆ Test Solution: {test_solution}")
            print(f"üîç Verification: {result.verification}")
        except Exception as e:
            print(f"‚ùå Verifier Error: {e}")
        
        # Test 3: LLM Reasoner + Symbolic Solver Integration
        print("\n[3] Testing LLM Reasoner + Symbolic Solver Integration...")
        print("-" * 50)
        try:
            # Use one of our actual test problems with similar examples
            test_query = "Two numbers sum to 50 and their difference is 10. What are the numbers?"
            similar_examples = [
                {
                    "text": "Two numbers add up to 30 and their difference is 6. Find the numbers.",
                    "equations": ["x + y = 30", "x - y = 6"]
                },
                {
                    "text": "The sum of two numbers is 40 and their difference is 8. What are they?",
                    "equations": ["x + y = 40", "x - y = 8"]
                },
                {
                    "text": "Find two numbers whose sum is 20 and difference is 4.",
                    "equations": ["x + y = 20", "x - y = 4"]
                }
            ]
            
            # Step 1: LLM extracts equations
            start_time = time.time()
            llm_result = self.llm_reasoner(
                query_text=test_query,
                canonical_equations=[],
                retrieved_examples=similar_examples
            )
            llm_time = time.time() - start_time
            
            print(f"‚úÖ LLM Reasoner: {'SUCCESS' if llm_result.success else 'PARTIAL'}")
            print(f"‚è± LLM Time: {llm_time:.3f} seconds")
            print(f"üìù Extracted Equations: {llm_result.llm_equations}")
            
            # Step 2: Symbolic solver solves the equations
            if llm_result.llm_equations:
                print(f"\nüîÑ Now testing Symbolic Solver with LLM equations...")
                start_time = time.time()
                solver_result = self.symbolic_solver(llm_result.llm_equations)
                solver_time = time.time() - start_time
                
                print(f"‚úÖ Symbolic Solver: {'SUCCESS' if solver_result.success else 'FAILED'}")
                print(f"‚è± Solver Time: {solver_time:.3f} seconds")
                print(f"üßÆ Final Solution: {solver_result.solution}")
                print(f"üîç Residuals: {solver_result.residuals}")
                
                # Step 3: Verify the solution
                if solver_result.success:
                    print(f"\nüîÑ Verifying solution...")
                    verify_result = self.verifier(llm_result.llm_equations, solver_result.solution)
                    print(f"‚úÖ Verification: {'PASSED' if verify_result.verification['ok'] else 'FAILED'}")
                    print(f"üîç Verification Details: {verify_result.verification}")
            else:
                print(f"‚ö†Ô∏è No equations extracted by LLM to solve")
                
        except Exception as e:
            print(f"‚ùå Integration Test Error: {e}")
            import traceback
            traceback.print_exc()

    def run_comprehensive_pipeline_tests(self):
        """Run comprehensive tests through the complete pipeline"""
        print("\nüöÄ COMPREHENSIVE PIPELINE TESTS")
        print("=" * 80)
        
        # Test cases covering different problem types and expected outcomes
        test_cases = [
            {
                "name": "Linear System (Symbolic)",
                "query": "Two numbers sum to 50 and their difference is 10. What are the numbers?",
                "expected_type": "symbolic",
                "description": "Should be solved symbolically with exact solution"
            },
            {
                "name": "Speed Problem (LLM)",
                "query": "A car travels 120 km in 2 hours. What is its speed?",
                "expected_type": "llm",
                "description": "Should use LLM reasoning for speed calculation"
            },
            {
                "name": "Cost Calculation (LLM)",
                "query": "If a pizza costs $18 and you order 3 pizzas, what's the total cost?",
                "expected_type": "llm",
                "description": "Should use LLM for multiplication reasoning"
            },
            {
                "name": "Area Problem (LLM)",
                "query": "A rectangle has length 12 cm and width 8 cm. What is its area?",
                "expected_type": "llm",
                "description": "Should use LLM for area formula application"
            },
            {
                "name": "Complex Word Problem (LLM)",
                "query": "A train leaves station A at 9 AM traveling at 60 km/h. Another train leaves station B at 10 AM traveling at 80 km/h. If the stations are 300 km apart, when will they meet?",
                "expected_type": "llm",
                "description": "Should use LLM for complex multi-step reasoning"
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n[{i}] {test_case['name']}")
            print("=" * 60)
            print(f"Query: {test_case['query']}")
            print(f"Expected: {test_case['expected_type']} solution")
            print(f"Description: {test_case['description']}")
            print()
            
            # Run through complete pipeline
            start_time = time.time()
            try:
                result = self.pipeline(test_case['query'], top_k=5, explain=True)
                total_time = time.time() - start_time
                
                # Update performance metrics
                self.performance_metrics['total_queries'] += 1
                self.performance_metrics['total_time'] += total_time
                
                # Analyze result type
                result_type = getattr(result, 'result_type', 'unknown')
                if result_type == 'symbolic':
                    self.performance_metrics['symbolic_solutions'] += 1
                elif result_type == 'llm':
                    self.performance_metrics['llm_solutions'] += 1
                else:
                    self.performance_metrics['unresolved'] += 1
                
                # Display comprehensive results
                self._display_pipeline_results(result, total_time, test_case)
                
            except Exception as e:
                print(f"‚ùå Pipeline failed: {e}")
                import traceback
                traceback.print_exc()
            
            print("\n" + "="*60)

    def _display_pipeline_results(self, result, total_time, test_case):
        """Display comprehensive pipeline results"""
        result_type = getattr(result, 'result_type', 'unknown')
        
        print(f"üìä PIPELINE RESULTS:")
        print(f"   Result Type: {result_type}")
        print(f"   Total Time: {total_time:.3f} seconds")
        print(f"   Expected: {test_case['expected_type']}")
        print(f"   Match: {'‚úÖ' if result_type == test_case['expected_type'] else '‚ö†Ô∏è'}")
        
        # Show retrieved similar problems
        results = getattr(result, 'results', [])
        if results:
            print(f"\nüìã RETRIEVED SIMILAR PROBLEMS ({len(results)}):")
            for j, res in enumerate(results[:3], 1):  # Show top 3
                similarity = res.get('similarity', 0)
                text = res.get('text', '')[:120] + "..."
                print(f"   [{j}] Similarity: {similarity:.4f}")
                print(f"       Text: {text}")
                
                # Track similarity scores
                self.performance_metrics['similarity_scores'].append(similarity)
        
        # Show extracted equations
        equations = getattr(result, 'equations', None)
        if equations:
            print(f"\nüìò EXTRACTED EQUATIONS ({len(equations)}):")
            for eq in equations:
                print(f"   ‚Ä¢ {eq}")
        
        # Show canonical equations
        canonical = getattr(result, 'canonical_equations', None)
        if canonical:
            print(f"\nüîß CANONICAL EQUATIONS ({len(canonical)}):")
            for eq in canonical:
                print(f"   ‚Ä¢ {eq} (type: {type(eq).__name__})")
        
        # Show solution
        solution = getattr(result, 'solution', None)
        if solution:
            print(f"\nüßÆ SOLUTION:")
            for var, val in solution.items():
                print(f"   {var} = {val}")
            
            # Show residuals for symbolic solutions
            residuals = getattr(result, 'residuals', None)
            if residuals:
                print(f"\nüîç VERIFICATION RESIDUALS:")
                for eq, val in residuals.items():
                    if isinstance(val, dict):
                        satisfied = val.get('satisfied', False)
                        value = val.get('value', 'N/A')
                        status = "‚úì" if satisfied else "‚úó"
                        print(f"   {status} {eq}: {value}")
                    else:
                        print(f"   ‚Ä¢ {eq}: {val}")
        
        # Show LLM reasoning if available
        reasoning = getattr(result, 'reasoning', None)
        if reasoning:
            print(f"\nü§ñ LLM REASONING:")
            print(textwrap.fill(reasoning[:300] + "...", width=70))
        
        # Show note if unresolved
        note = getattr(result, 'note', None)
        if note:
            print(f"\n‚ÑπÔ∏è NOTE: {note}")

    def run_performance_analysis(self):
        """Run performance analysis and generate metrics"""
        print("\nüìä PERFORMANCE ANALYSIS")
        print("=" * 80)
        
        if self.performance_metrics['total_queries'] == 0:
            print("No queries processed for analysis.")
            return
        
        # Calculate metrics
        total_queries = self.performance_metrics['total_queries']
        avg_time = self.performance_metrics['total_time'] / total_queries
        
        symbolic_rate = (self.performance_metrics['symbolic_solutions'] / total_queries) * 100
        llm_rate = (self.performance_metrics['llm_solutions'] / total_queries) * 100
        unresolved_rate = (self.performance_metrics['unresolved'] / total_queries) * 100
        
        avg_similarity = np.mean(self.performance_metrics['similarity_scores']) if self.performance_metrics['similarity_scores'] else 0
        
        print(f"üìà OVERALL PERFORMANCE METRICS:")
        print(f"   Total Queries Processed: {total_queries}")
        print(f"   Average Processing Time: {avg_time:.3f} seconds")
        print(f"   Total Processing Time: {self.performance_metrics['total_time']:.3f} seconds")
        print()
        
        print(f"üéØ SOLUTION DISTRIBUTION:")
        print(f"   Symbolic Solutions: {self.performance_metrics['symbolic_solutions']} ({symbolic_rate:.1f}%)")
        print(f"   LLM Solutions: {self.performance_metrics['llm_solutions']} ({llm_rate:.1f}%)")
        print(f"   Unresolved: {self.performance_metrics['unresolved']} ({unresolved_rate:.1f}%)")
        print()
        
        print(f"üîç RETRIEVAL QUALITY:")
        print(f"   Average Similarity Score: {avg_similarity:.4f}")
        print(f"   Similarity Range: {min(self.performance_metrics['similarity_scores']):.4f} - {max(self.performance_metrics['similarity_scores']):.4f}")
        print()
        
        # Performance recommendations
        print(f"üí° PERFORMANCE INSIGHTS:")
        if avg_time > 10:
            print("   ‚ö†Ô∏è Processing time is high - consider optimization")
        else:
            print("   ‚úÖ Processing time is acceptable")
        
        if unresolved_rate > 50:
            print("   ‚ö†Ô∏è High unresolved rate - may need better equation extraction")
        else:
            print("   ‚úÖ Good resolution rate")
        
        if avg_similarity < 0.5:
            print("   ‚ö†Ô∏è Low similarity scores - may need better embeddings")
        else:
            print("   ‚úÖ Good similarity retrieval")

    def run_interactive_demo(self):
        """Run interactive demo mode"""
        print("\nüéÆ INTERACTIVE DEMO MODE")
        print("=" * 80)
        print("Enter your own mathematical problems to test the complete pipeline!")
        print("Type 'quit' to exit, 'metrics' to see performance, 'help' for examples")
        print("=" * 80)
        
        while True:
            try:
                query = input("\nüîç Enter your math problem: ").strip()
                
                if not query:
                    continue
                
                if query.lower() in ['quit', 'exit', 'q']:
                    print("üëã Goodbye!")
                    break
                
                if query.lower() == 'metrics':
                    self.run_performance_analysis()
                    continue
                
                if query.lower() == 'help':
                    print("\nüìö Example problems to try:")
                    print("‚Ä¢ Two numbers sum to 50 and their difference is 10. What are the numbers?")
                    print("‚Ä¢ A car travels 120 km in 2 hours. What is its speed?")
                    print("‚Ä¢ If a pizza costs $18 and you order 3 pizzas, what's the total cost?")
                    print("‚Ä¢ A rectangle has length 12 cm and width 8 cm. What is its area?")
                    continue
                
                print(f"\nüöÄ Processing: {query}")
                print("-" * 60)
                
                start_time = time.time()
                result = self.pipeline(query, top_k=3, explain=True)
                total_time = time.time() - start_time
                
                # Update metrics
                self.performance_metrics['total_queries'] += 1
                self.performance_metrics['total_time'] += total_time
                
                # Display results
                self._display_pipeline_results(result, total_time, {
                    'name': 'Interactive Query',
                    'expected_type': 'unknown'
                })
                
            except KeyboardInterrupt:
                print("\n\nüëã Goodbye!")
                break
            except Exception as e:
                print(f"‚ùå Error: {e}")

    def run_complete_demo(self):
        """Run the complete demonstration"""
        print("üéØ CALCMATE COMPLETE NEURO-SYMBOLIC PIPELINE DEMONSTRATION")
        print("=" * 80)
        print("This demo showcases the complete end-to-end pipeline:")
        print("‚Ä¢ Mathematical similarity retrieval")
        print("‚Ä¢ Equation extraction and canonicalization")
        print("‚Ä¢ Symbolic equation solving")
        print("‚Ä¢ CTransformers LLM reasoning")
        print("‚Ä¢ Solution verification")
        print("‚Ä¢ Performance analysis")
        print("=" * 80)
        
        # Load complete system
        if not self.load_complete_system():
            return
        
        # Test individual components
        self.test_individual_components()
        
        # Skip comprehensive pipeline tests for now - focus on solver
        print("\n‚è≠Ô∏è Skipping comprehensive pipeline tests - focusing on solver functionality")
        
        # Skip performance analysis for now
        print("‚è≠Ô∏è Skipping performance analysis - focusing on solver functionality")
        
        # Interactive demo
        try:
            response = input("\nüéÆ Would you like to try interactive mode? (y/n): ").strip().lower()
            if response in ['y', 'yes']:
                self.run_interactive_demo()
        except (KeyboardInterrupt, EOFError):
            print("\n\nüëã Goodbye!")
        
        print("\nüéâ COMPLETE PIPELINE DEMONSTRATION FINISHED!")
        print("=" * 80)
        print("‚úÖ All components tested successfully")
        print("‚úÖ End-to-end pipeline verified")
        print("‚úÖ Performance metrics collected")
        print("‚úÖ Interactive mode demonstrated")
        print("\nüí° The complete neuro-symbolic system is ready for production use!")


def main():
    """Main demo runner"""
    demo = CompletePipelineDemo()
    demo.run_complete_demo()


if __name__ == "__main__":
    main()
